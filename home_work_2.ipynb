{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYkcFqoFMa4ovgZ4hCwUrm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VladShajdulin/OTUS/blob/main/home_work_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "zVe6GduqDiEi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low, high = -10, 10\n",
        "n_size = 20000\n",
        "\n",
        "torch.manual_seed(142)\n",
        "X = (high - low) * torch.rand((n_size, 2), dtype=torch.float64) + low\n",
        "y = torch.sin(X[:,0] + 2 * X[:,1]) * torch.exp(-(2 * X[:,0] + X[:,1]) ** 2)\n",
        "y = torch.unsqueeze(y, -1)"
      ],
      "metadata": {
        "id": "Ja3ZQIUIJXCI"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=142)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=142)\n",
        "\n",
        "print(f'Training samples: {X_train.size()[0]}')\n",
        "print(f'Validating samples: {X_val.size()[0]}')\n",
        "print(f'Training samples: {X_test.size()[0]}')"
      ],
      "metadata": {
        "id": "Lx5dIrVoxVaA",
        "outputId": "237888bd-0342-416d-ab5f-7d8f3b50c8ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 14000\n",
            "Validating samples: 3000\n",
            "Training samples: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class XY_dataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.size()[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "xYJ6VGANtvkf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer, device):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # Compute prediction error\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "\n",
        "      # Backpropagation\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      if batch % 10 == 0:\n",
        "          loss, current = loss.item(), (batch + 1) * len(X)\n",
        "          print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def val(X, y, model, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y).item()\n",
        "    rel_error = abs(y - pred).mean() / abs(y).mean()\n",
        "\n",
        "  print(f\"\\n Val loss: {loss:>7f}, mean relative error: {rel_error:>5f} \\n\")"
      ],
      "metadata": {
        "id": "sxyfJcBb25uV"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = nn.Sequential(\n",
        "    nn.Linear(2, 20, dtype=torch.float64),\n",
        "    nn.Softsign(),\n",
        "    nn.Linear(20, 20, dtype=torch.float64),\n",
        "    nn.Softsign(),\n",
        "    nn.Linear(20, 10, dtype=torch.float64),\n",
        "    nn.Softsign(),\n",
        "    nn.Linear(10, 1, dtype=torch.float64)\n",
        ")"
      ],
      "metadata": {
        "id": "B5ofmUZqzzer"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_loader = XY_dataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_loader, shuffle=True, batch_size=batch_size)\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else 'cpu'\n",
        "print('Device', device)"
      ],
      "metadata": {
        "id": "u9nB-mvnzDre",
        "outputId": "cc0f123e-3c41-46fb-f390-b8c1ae3cf982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_1.parameters(), lr=1e-5)\n",
        "epochs = 10\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train(train_loader, model_1, loss_fn, optimizer, device)\n",
        "  val(X_val, y_val, model_1, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "M4XNSnPL7pDY",
        "outputId": "bc695fd6-ec45-490a-97ec-371515d7f57b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.016614  [  256/14000]\n",
            "loss: 0.019762  [ 2816/14000]\n",
            "loss: 0.018071  [ 5376/14000]\n",
            "loss: 0.016339  [ 7936/14000]\n",
            "loss: 0.017288  [10496/14000]\n",
            "loss: 0.014980  [13056/14000]\n",
            "\n",
            " Val loss: 0.015918, mean relative error: 1.233008 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.015198  [  256/14000]\n",
            "loss: 0.014535  [ 2816/14000]\n",
            "loss: 0.011093  [ 5376/14000]\n",
            "loss: 0.012702  [ 7936/14000]\n",
            "loss: 0.013052  [10496/14000]\n",
            "loss: 0.019879  [13056/14000]\n",
            "\n",
            " Val loss: 0.015913, mean relative error: 1.231868 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.008144  [  256/14000]\n",
            "loss: 0.018846  [ 2816/14000]\n",
            "loss: 0.016714  [ 5376/14000]\n",
            "loss: 0.013671  [ 7936/14000]\n",
            "loss: 0.013744  [10496/14000]\n",
            "loss: 0.011333  [13056/14000]\n",
            "\n",
            " Val loss: 0.015910, mean relative error: 1.229230 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.026441  [  256/14000]\n",
            "loss: 0.025604  [ 2816/14000]\n",
            "loss: 0.016720  [ 5376/14000]\n",
            "loss: 0.020985  [ 7936/14000]\n",
            "loss: 0.016649  [10496/14000]\n",
            "loss: 0.015629  [13056/14000]\n",
            "\n",
            " Val loss: 0.015906, mean relative error: 1.223899 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.015493  [  256/14000]\n",
            "loss: 0.016809  [ 2816/14000]\n",
            "loss: 0.021366  [ 5376/14000]\n",
            "loss: 0.014640  [ 7936/14000]\n",
            "loss: 0.041595  [10496/14000]\n",
            "loss: 0.013476  [13056/14000]\n",
            "\n",
            " Val loss: 0.015902, mean relative error: 1.223704 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.011900  [  256/14000]\n",
            "loss: 0.018465  [ 2816/14000]\n",
            "loss: 0.011988  [ 5376/14000]\n",
            "loss: 0.012732  [ 7936/14000]\n",
            "loss: 0.012708  [10496/14000]\n",
            "loss: 0.014826  [13056/14000]\n",
            "\n",
            " Val loss: 0.015899, mean relative error: 1.222601 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.018985  [  256/14000]\n",
            "loss: 0.017981  [ 2816/14000]\n",
            "loss: 0.023515  [ 5376/14000]\n",
            "loss: 0.006416  [ 7936/14000]\n",
            "loss: 0.022108  [10496/14000]\n",
            "loss: 0.020649  [13056/14000]\n",
            "\n",
            " Val loss: 0.015895, mean relative error: 1.225555 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.013159  [  256/14000]\n",
            "loss: 0.014490  [ 2816/14000]\n",
            "loss: 0.012389  [ 5376/14000]\n",
            "loss: 0.012576  [ 7936/14000]\n",
            "loss: 0.015863  [10496/14000]\n",
            "loss: 0.007470  [13056/14000]\n",
            "\n",
            " Val loss: 0.015891, mean relative error: 1.223962 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.007519  [  256/14000]\n",
            "loss: 0.020807  [ 2816/14000]\n",
            "loss: 0.009685  [ 5376/14000]\n",
            "loss: 0.013194  [ 7936/14000]\n",
            "loss: 0.009493  [10496/14000]\n",
            "loss: 0.022585  [13056/14000]\n",
            "\n",
            " Val loss: 0.015888, mean relative error: 1.223033 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.015703  [  256/14000]\n",
            "loss: 0.014589  [ 2816/14000]\n",
            "loss: 0.013468  [ 5376/14000]\n",
            "loss: 0.010558  [ 7936/14000]\n",
            "loss: 0.022504  [10496/14000]\n",
            "loss: 0.011435  [13056/14000]\n",
            "\n",
            " Val loss: 0.015884, mean relative error: 1.219273 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resid = y_test - model_1(X_test)\n",
        "resid"
      ],
      "metadata": {
        "id": "b7xKtpLu9mZ6",
        "outputId": "df67f751-4de5-4e25-ea0c-b2fe4844562e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0028],\n",
              "        [-0.0070],\n",
              "        [ 0.0884],\n",
              "        ...,\n",
              "        [ 0.0184],\n",
              "        [ 0.0039],\n",
              "        [ 0.0036]], dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    }
  ]
}