{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d31dd171-fd74-4c12-b24a-9bf5eef2377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from re import search\n",
    "import json\n",
    "from time import sleep\n",
    "from random import uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7780f3-f2b8-4991-b96e-5c6b636e2352",
   "metadata": {},
   "source": [
    "# Парсинг \n",
    "Вдохновившись новостями по нобелевской неделе, для парсинга я выбрал сайт Naked Science, который содержит научнопопулярные статьи и новости из мира науки. Из каждой статьи можно вытащить ее название, автора, аннотацию, индекс важности (оценка автором важности исследования/открытия для науки), дату публикации, сам текст статьи, хэштеги и количество просмотров в качестве целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95fa7f14-e58e-4d7c-9f93-1f3b2ba8c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date, form='%d.%m.%Y'):\n",
    "    mapper = {\n",
    "        'января': '01',\n",
    "        'февраля': '02',\n",
    "        'марта': '03',\n",
    "        'апреля': '04',\n",
    "        'мая': '05',\n",
    "        'июня': '06',\n",
    "        'июля': '07',\n",
    "        'августа': '08',\n",
    "        'сентября': '09',\n",
    "        'октября': '10',\n",
    "        'ноября': '11',\n",
    "        'декабря': '12'\n",
    "    }\n",
    "    if search(r'\\d{1,2}\\.\\d{2}\\.\\d{4}', date):\n",
    "        return date\n",
    "    else:\n",
    "        date = date.split()\n",
    "        day = '0' + date[0] if len(date[0]) < 2 else date[0]\n",
    "        return '.'.join((day, mapper[date[1]], '2025'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0748981a-c70b-4141-af21-e70878805959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(obj):\n",
    "    header = obj.find('a', attrs={'class': 'animate-custom'})\n",
    "    link = header.attrs['href'].strip()\n",
    "    \n",
    "    title = header.get_text().split()\n",
    "    imp_ind = float(title[-1])\n",
    "    title = ' '.join(title[:-1])\n",
    "\n",
    "    author = obj.find(lambda tag: tag.name == 'div' and tag.get('class') == ['meta-item', 'meta-item_author'])\n",
    "    author = author.string.strip()\n",
    "\n",
    "    date = obj.find('span', attrs={'class': 'echo_date'}).string\n",
    "    date = parse_date(date.split(', ')[0])\n",
    "\n",
    "    views = obj.find('span', attrs={'class': 'fvc-count'}).string\n",
    "    views = int(views.replace(' ', ''))\n",
    "\n",
    "    annot = obj.find('p').string.strip()\n",
    "\n",
    "    tags = obj.find(lambda tag: tag.name == 'div' and tag.get('class') == ['terms-items', 'grid'])\n",
    "    tags = tags.find_all('div', attrs={'class': 'terms-item'})\n",
    "    tags = [t.get_text().replace('#', '').strip().lower() for t in tags]\n",
    "\n",
    "    return {\n",
    "        'title': title,\n",
    "        'author': author,\n",
    "        'date': date,\n",
    "        'imp_ind': imp_ind,\n",
    "        'views': views,\n",
    "        'annot': annot,\n",
    "        'tags': tags,\n",
    "        'link': link\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a60595b-bf5f-4cac-bca5-37beb6558647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing page 1/10\n",
      "processing page 2/10\n",
      "processing page 3/10\n",
      "processing page 4/10\n",
      "processing page 5/10\n",
      "processing page 6/10\n",
      "processing page 7/10\n",
      "processing page 8/10\n",
      "processing page 9/10\n",
      "processing page 10/10\n",
      "\n",
      " --- 10/10 pages have been successfully parsed ---\n"
     ]
    }
   ],
   "source": [
    "user_ag = UserAgent()\n",
    "main_link = 'https://naked-science.ru/article/page/'\n",
    "pages = 10\n",
    "articles = []\n",
    "attemps = 0\n",
    "success = []\n",
    "\n",
    "for i in range(1, pages + 1):\n",
    "    if i % 5 == 0:\n",
    "        print(f'processing page {i}/{pages}')\n",
    "        with open('articles_links.json', 'w', encoding='UTF-8') as f:\n",
    "            json.dump(articles, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    for j in range(3):\n",
    "        sleep(uniform(1.1, 1.9))\n",
    "        response = requests.get(main_link + f'{i}/', headers={'User-Agent': user_ag.random})\n",
    "        if not response.ok:\n",
    "            print(f'\\n  WARNING: page {i} parsing failed\\n')\n",
    "            continue\n",
    "        else:\n",
    "            success.append(i)\n",
    "            attemps = 0\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            news = soup.find('div', attrs={'class': 'news-items'})\n",
    "            news = news.find_all(lambda tag: tag.name == 'div' and tag.get('class') == ['news-item-left', 'with-bookmark'])\n",
    "            articles = articles + [get_info(x) for x in news if get_info(x) not in articles]\n",
    "            break\n",
    "    else:\n",
    "        attemps += 1\n",
    "\n",
    "    if attemps > 3:\n",
    "        print(f'\\n  WARNING: {i - 1} pages processed')\n",
    "        break\n",
    "\n",
    "\n",
    "print(f'\\n --- {len(success)}/{pages} pages have been successfully parsed ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8dd4189-f40b-4774-bdd0-3591fc775850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d1235f7-b7d8-4572-9547-84870d05e8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 193)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smth = [i['title'] for i in articles]\n",
    "len(smth), len(set(smth))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my-env]",
   "language": "python",
   "name": "conda-env-my-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
